<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ilpyt.envs.subproc_vec_env API documentation</title>
<meta name="description" content="`SubprocVecEnv` is a vectorized OpenAI Gym environment object, implemented in a
parallel fashion. This is good for high-throughput training and â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ilpyt.envs.subproc_vec_env</code></h1>
</header>
<section id="section-intro">
<p><code><a title="ilpyt.envs.subproc_vec_env.SubprocVecEnv" href="#ilpyt.envs.subproc_vec_env.SubprocVecEnv">SubprocVecEnv</a></code> is a vectorized OpenAI Gym environment object, implemented in a
parallel fashion. This is good for high-throughput training and testing. Adapted
from: <a href="https://github.com/openai/baselines/">https://github.com/openai/baselines/</a></p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
`SubprocVecEnv` is a vectorized OpenAI Gym environment object, implemented in a 
parallel fashion. This is good for high-throughput training and testing. Adapted 
from: https://github.com/openai/baselines/
&#34;&#34;&#34;

import contextlib
import multiprocessing as mp
import os

import numpy as np

from ilpyt.envs.vec_env import VecEnv

# https://github.com/openai/baselines/blob/master/baselines/common/vec_env/subproc_vec_env.py


@contextlib.contextmanager
def clear_mpi_env_vars():
    &#34;&#34;&#34;
    From mpi4py import MPI will call MPI_Init by default.  If the child process has MPI environment variables, MPI will think that the child process is an MPI process just like the parent and do bad things such as hang.
    This context manager is a hacky way to clear those environment variables temporarily such as when we are starting multiprocessing.
    Processes.
    &#34;&#34;&#34;
    removed_environment = {}
    for k, v in list(os.environ.items()):
        for prefix in [&#39;OMPI_&#39;, &#39;PMI_&#39;]:
            if k.startswith(prefix):
                removed_environment[k] = v
                del os.environ[k]
    try:
        yield
    finally:
        os.environ.update(removed_environment)


class CloudpickleWrapper(object):
    &#34;&#34;&#34;
    Uses cloudpickle to serialize contents (otherwise multiprocessing tries to 
    use pickle).
    &#34;&#34;&#34;

    def __init__(self, x):
        self.x = x

    def __getstate__(self):
        import cloudpickle

        return cloudpickle.dumps(self.x)

    def __setstate__(self, ob):
        import pickle

        self.x = pickle.loads(ob)


def worker(remote, parent_remote, env_fn_wrappers):
    def step_env(env, action):
        ob, reward, done, info = env.step(action)
        if done:
            ob = env.reset()
        return ob, reward, done, info

    parent_remote.close()
    envs = [env_fn_wrapper() for env_fn_wrapper in env_fn_wrappers.x]
    try:
        while True:
            cmd, data = remote.recv()
            if cmd == &#39;step&#39;:
                remote.send(
                    [step_env(env, action) for env, action in zip(envs, data)]
                )
            elif cmd == &#39;reset&#39;:
                remote.send([env.reset() for env in envs])
            elif cmd == &#39;render&#39;:
                remote.send([env.render(mode=&#39;rgb_array&#39;) for env in envs])
            elif cmd == &#39;close&#39;:
                remote.close()
                break
            elif cmd == &#39;get_spaces_spec&#39;:
                remote.send(
                    CloudpickleWrapper(
                        (
                            envs[0].observation_space,
                            envs[0].action_space,
                            envs[0].spec,
                        )
                    )
                )
            else:
                raise NotImplementedError
    except KeyboardInterrupt:
        print(&#39;SubprocVecEnv worker: got KeyboardInterrupt&#39;)
    finally:
        for env in envs:
            env.close()


class SubprocVecEnv(VecEnv):
    &#34;&#34;&#34;
    VecEnv that runs multiple environments in parallel in subproceses and 
    communicates with them via pipes.
    Recommended to use when num_envs &gt; 1 and step() can be a bottleneck.
    &#34;&#34;&#34;

    def __init__(self, env_fns, spaces=None, context=&#39;spawn&#39;, in_series=1):
        &#34;&#34;&#34;
        Parameters
        ----------
        env_fns: iterable of callables
            functions that create environments to 
            run in subprocesses. Need to be cloud-pickleable
        in_series: number of environments to run in series in a single process
            (e.g. when len(env_fns) == 12 and in_series == 3, it will run 4 
            processes, each running 3 envs in series)
        &#34;&#34;&#34;
        self.waiting = False
        self.closed = False
        self.in_series = in_series
        nenvs = len(env_fns)
        assert (
            nenvs % in_series == 0
        ), &#34;Number of envs must be divisible by number of envs to run in series&#34;
        self.nremotes = nenvs // in_series
        env_fns = np.array_split(env_fns, self.nremotes)
        ctx = mp.get_context(context)
        self.remotes, self.work_remotes = zip(
            *[ctx.Pipe() for _ in range(self.nremotes)]
        )
        self.ps = [
            ctx.Process(
                target=worker,
                args=(work_remote, remote, CloudpickleWrapper(env_fn)),
            )
            for (work_remote, remote, env_fn) in zip(
                self.work_remotes, self.remotes, env_fns
            )
        ]
        for p in self.ps:
            p.daemon = True  # if the main process crashes, we should not cause things to hang
            with clear_mpi_env_vars():
                p.start()
        for remote in self.work_remotes:
            remote.close()

        self.remotes[0].send((&#39;get_spaces_spec&#39;, None))
        observation_space, action_space, self.spec = self.remotes[0].recv().x
        self.viewer = None
        VecEnv.__init__(self, nenvs, observation_space, action_space)

    def step_async(self, actions):
        self._assert_not_closed()
        actions = np.array_split(actions, self.nremotes)
        for remote, action in zip(self.remotes, actions):
            remote.send((&#39;step&#39;, action))
        self.waiting = True

    def step_wait(self):
        self._assert_not_closed()
        results = [remote.recv() for remote in self.remotes]
        results = _flatten_list(results)
        self.waiting = False
        obs, rews, dones, infos = zip(*results)
        return _flatten_obs(obs), np.stack(rews), np.stack(dones), infos

    def reset(self):
        self._assert_not_closed()
        for remote in self.remotes:
            remote.send((&#39;reset&#39;, None))
        obs = [remote.recv() for remote in self.remotes]
        obs = _flatten_list(obs)
        return _flatten_obs(obs)

    def close_extras(self):
        self.closed = True
        if self.waiting:
            for remote in self.remotes:
                remote.recv()
        for remote in self.remotes:
            remote.send((&#39;close&#39;, None))
        for p in self.ps:
            p.join()

    def get_images(self):
        self._assert_not_closed()
        for pipe in self.remotes:
            pipe.send((&#39;render&#39;, None))
        imgs = [pipe.recv() for pipe in self.remotes]
        imgs = _flatten_list(imgs)
        return imgs

    def _assert_not_closed(self):
        assert (
            not self.closed
        ), &#34;Trying to operate on a SubprocVecEnv after calling close()&#34;

    def __del__(self):
        if not self.closed:
            self.close()


def _flatten_obs(obs):
    assert isinstance(obs, (list, tuple))
    assert len(obs) &gt; 0

    if isinstance(obs[0], dict):
        keys = obs[0].keys()
        return {k: np.stack([o[k] for o in obs]) for k in keys}
    else:
        return np.stack(obs)


def _flatten_list(x):
    assert isinstance(x, (list, tuple))
    assert len(x) &gt; 0
    assert all([len(x_) &gt; 0 for x_ in x])

    return [x__ for x_ in x for x__ in x_]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ilpyt.envs.subproc_vec_env.clear_mpi_env_vars"><code class="name flex">
<span>def <span class="ident">clear_mpi_env_vars</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>From mpi4py import MPI will call MPI_Init by default.
If the child process has MPI environment variables, MPI will think that the child process is an MPI process just like the parent and do bad things such as hang.
This context manager is a hacky way to clear those environment variables temporarily such as when we are starting multiprocessing.
Processes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@contextlib.contextmanager
def clear_mpi_env_vars():
    &#34;&#34;&#34;
    From mpi4py import MPI will call MPI_Init by default.  If the child process has MPI environment variables, MPI will think that the child process is an MPI process just like the parent and do bad things such as hang.
    This context manager is a hacky way to clear those environment variables temporarily such as when we are starting multiprocessing.
    Processes.
    &#34;&#34;&#34;
    removed_environment = {}
    for k, v in list(os.environ.items()):
        for prefix in [&#39;OMPI_&#39;, &#39;PMI_&#39;]:
            if k.startswith(prefix):
                removed_environment[k] = v
                del os.environ[k]
    try:
        yield
    finally:
        os.environ.update(removed_environment)</code></pre>
</details>
</dd>
<dt id="ilpyt.envs.subproc_vec_env.worker"><code class="name flex">
<span>def <span class="ident">worker</span></span>(<span>remote, parent_remote, env_fn_wrappers)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def worker(remote, parent_remote, env_fn_wrappers):
    def step_env(env, action):
        ob, reward, done, info = env.step(action)
        if done:
            ob = env.reset()
        return ob, reward, done, info

    parent_remote.close()
    envs = [env_fn_wrapper() for env_fn_wrapper in env_fn_wrappers.x]
    try:
        while True:
            cmd, data = remote.recv()
            if cmd == &#39;step&#39;:
                remote.send(
                    [step_env(env, action) for env, action in zip(envs, data)]
                )
            elif cmd == &#39;reset&#39;:
                remote.send([env.reset() for env in envs])
            elif cmd == &#39;render&#39;:
                remote.send([env.render(mode=&#39;rgb_array&#39;) for env in envs])
            elif cmd == &#39;close&#39;:
                remote.close()
                break
            elif cmd == &#39;get_spaces_spec&#39;:
                remote.send(
                    CloudpickleWrapper(
                        (
                            envs[0].observation_space,
                            envs[0].action_space,
                            envs[0].spec,
                        )
                    )
                )
            else:
                raise NotImplementedError
    except KeyboardInterrupt:
        print(&#39;SubprocVecEnv worker: got KeyboardInterrupt&#39;)
    finally:
        for env in envs:
            env.close()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ilpyt.envs.subproc_vec_env.CloudpickleWrapper"><code class="flex name class">
<span>class <span class="ident">CloudpickleWrapper</span></span>
<span>(</span><span>x)</span>
</code></dt>
<dd>
<div class="desc"><p>Uses cloudpickle to serialize contents (otherwise multiprocessing tries to
use pickle).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CloudpickleWrapper(object):
    &#34;&#34;&#34;
    Uses cloudpickle to serialize contents (otherwise multiprocessing tries to 
    use pickle).
    &#34;&#34;&#34;

    def __init__(self, x):
        self.x = x

    def __getstate__(self):
        import cloudpickle

        return cloudpickle.dumps(self.x)

    def __setstate__(self, ob):
        import pickle

        self.x = pickle.loads(ob)</code></pre>
</details>
</dd>
<dt id="ilpyt.envs.subproc_vec_env.SubprocVecEnv"><code class="flex name class">
<span>class <span class="ident">SubprocVecEnv</span></span>
<span>(</span><span>env_fns, spaces=None, context='spawn', in_series=1)</span>
</code></dt>
<dd>
<div class="desc"><p>VecEnv that runs multiple environments in parallel in subproceses and
communicates with them via pipes.
Recommended to use when num_envs &gt; 1 and step() can be a bottleneck.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>env_fns</code></strong> :&ensp;<code>iterable</code> of <code>callables</code></dt>
<dd>functions that create environments to
run in subprocesses. Need to be cloud-pickleable</dd>
<dt><strong><code>in_series</code></strong> :&ensp;<code>number</code> of <code>environments to run in series in a single process</code></dt>
<dd>(e.g. when len(env_fns) == 12 and in_series == 3, it will run 4
processes, each running 3 envs in series)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SubprocVecEnv(VecEnv):
    &#34;&#34;&#34;
    VecEnv that runs multiple environments in parallel in subproceses and 
    communicates with them via pipes.
    Recommended to use when num_envs &gt; 1 and step() can be a bottleneck.
    &#34;&#34;&#34;

    def __init__(self, env_fns, spaces=None, context=&#39;spawn&#39;, in_series=1):
        &#34;&#34;&#34;
        Parameters
        ----------
        env_fns: iterable of callables
            functions that create environments to 
            run in subprocesses. Need to be cloud-pickleable
        in_series: number of environments to run in series in a single process
            (e.g. when len(env_fns) == 12 and in_series == 3, it will run 4 
            processes, each running 3 envs in series)
        &#34;&#34;&#34;
        self.waiting = False
        self.closed = False
        self.in_series = in_series
        nenvs = len(env_fns)
        assert (
            nenvs % in_series == 0
        ), &#34;Number of envs must be divisible by number of envs to run in series&#34;
        self.nremotes = nenvs // in_series
        env_fns = np.array_split(env_fns, self.nremotes)
        ctx = mp.get_context(context)
        self.remotes, self.work_remotes = zip(
            *[ctx.Pipe() for _ in range(self.nremotes)]
        )
        self.ps = [
            ctx.Process(
                target=worker,
                args=(work_remote, remote, CloudpickleWrapper(env_fn)),
            )
            for (work_remote, remote, env_fn) in zip(
                self.work_remotes, self.remotes, env_fns
            )
        ]
        for p in self.ps:
            p.daemon = True  # if the main process crashes, we should not cause things to hang
            with clear_mpi_env_vars():
                p.start()
        for remote in self.work_remotes:
            remote.close()

        self.remotes[0].send((&#39;get_spaces_spec&#39;, None))
        observation_space, action_space, self.spec = self.remotes[0].recv().x
        self.viewer = None
        VecEnv.__init__(self, nenvs, observation_space, action_space)

    def step_async(self, actions):
        self._assert_not_closed()
        actions = np.array_split(actions, self.nremotes)
        for remote, action in zip(self.remotes, actions):
            remote.send((&#39;step&#39;, action))
        self.waiting = True

    def step_wait(self):
        self._assert_not_closed()
        results = [remote.recv() for remote in self.remotes]
        results = _flatten_list(results)
        self.waiting = False
        obs, rews, dones, infos = zip(*results)
        return _flatten_obs(obs), np.stack(rews), np.stack(dones), infos

    def reset(self):
        self._assert_not_closed()
        for remote in self.remotes:
            remote.send((&#39;reset&#39;, None))
        obs = [remote.recv() for remote in self.remotes]
        obs = _flatten_list(obs)
        return _flatten_obs(obs)

    def close_extras(self):
        self.closed = True
        if self.waiting:
            for remote in self.remotes:
                remote.recv()
        for remote in self.remotes:
            remote.send((&#39;close&#39;, None))
        for p in self.ps:
            p.join()

    def get_images(self):
        self._assert_not_closed()
        for pipe in self.remotes:
            pipe.send((&#39;render&#39;, None))
        imgs = [pipe.recv() for pipe in self.remotes]
        imgs = _flatten_list(imgs)
        return imgs

    def _assert_not_closed(self):
        assert (
            not self.closed
        ), &#34;Trying to operate on a SubprocVecEnv after calling close()&#34;

    def __del__(self):
        if not self.closed:
            self.close()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="ilpyt.envs.vec_env.VecEnv" href="vec_env.html#ilpyt.envs.vec_env.VecEnv">VecEnv</a></li>
<li>abc.ABC</li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="ilpyt.envs.vec_env.VecEnv" href="vec_env.html#ilpyt.envs.vec_env.VecEnv">VecEnv</a></b></code>:
<ul class="hlist">
<li><code><a title="ilpyt.envs.vec_env.VecEnv.close_extras" href="vec_env.html#ilpyt.envs.vec_env.VecEnv.close_extras">close_extras</a></code></li>
<li><code><a title="ilpyt.envs.vec_env.VecEnv.get_images" href="vec_env.html#ilpyt.envs.vec_env.VecEnv.get_images">get_images</a></code></li>
<li><code><a title="ilpyt.envs.vec_env.VecEnv.reset" href="vec_env.html#ilpyt.envs.vec_env.VecEnv.reset">reset</a></code></li>
<li><code><a title="ilpyt.envs.vec_env.VecEnv.step" href="vec_env.html#ilpyt.envs.vec_env.VecEnv.step">step</a></code></li>
<li><code><a title="ilpyt.envs.vec_env.VecEnv.step_async" href="vec_env.html#ilpyt.envs.vec_env.VecEnv.step_async">step_async</a></code></li>
<li><code><a title="ilpyt.envs.vec_env.VecEnv.step_wait" href="vec_env.html#ilpyt.envs.vec_env.VecEnv.step_wait">step_wait</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ilpyt.envs" href="index.html">ilpyt.envs</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ilpyt.envs.subproc_vec_env.clear_mpi_env_vars" href="#ilpyt.envs.subproc_vec_env.clear_mpi_env_vars">clear_mpi_env_vars</a></code></li>
<li><code><a title="ilpyt.envs.subproc_vec_env.worker" href="#ilpyt.envs.subproc_vec_env.worker">worker</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ilpyt.envs.subproc_vec_env.CloudpickleWrapper" href="#ilpyt.envs.subproc_vec_env.CloudpickleWrapper">CloudpickleWrapper</a></code></h4>
</li>
<li>
<h4><code><a title="ilpyt.envs.subproc_vec_env.SubprocVecEnv" href="#ilpyt.envs.subproc_vec_env.SubprocVecEnv">SubprocVecEnv</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>